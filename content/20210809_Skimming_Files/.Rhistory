"flipper_length_mm", "body_mass_g",
"cluster")
# turn cluster from a numerical varible into a factor (categorical) variable
df_with_clusters$cluster <- factor(df_with_clusters$cluster)
df_with_clusters %>% group_by(cluster) %>% tally()
df_with_clusters %>%
ggplot(aes(x = flipper_length_mm, bill_length_mm, color = cluster)) +
geom_point(size = 2) +
labs(title = "Palmer Penguins",
subtitle = "k = 3 clusters",
caption = "Math 32",
x = "flipper length (mm)",
y = "bill length (mm)") +
theme_minimal()
plot_truth <- df_penguins %>%
ggplot(aes(x = flipper_length_mm, bill_length_mm, color = species)) +
geom_point(size = 2) +
labs(title = "original data",
caption = "Math 32",
x = "flipper length (mm)",
y = "bill length (mm)") +
theme_minimal()
plot_empirical <- df_with_clusters %>%
ggplot(aes(x = flipper_length_mm, bill_length_mm, color = cluster)) +
geom_point(size = 2) +
labs(title = "k = 3 clusters",
caption = "Math 32",
x = "flipper length (mm)",
y = "bill length (mm)") +
theme_minimal()
# via patchwork package
plot_truth / plot_empirical
df_verification <- data.frame(df_penguins$species, clusters3$cluster)
colnames(df_verification) <- c("species", "cluster")
df_verification %>%
mutate(cluster_classification = case_when(cluster == 1 ~ "Adelie",
cluster == 2 ~ "Chinstrap",
TRUE ~ "Gentoo"))
df_verification <- data.frame(df_penguins$species, clusters3$cluster)
colnames(df_verification) <- c("species", "cluster")
df_verification %>%
mutate(cluster_classification = case_when(cluster == 1 ~ "Chinstrap",
cluster == 2 ~ "Adelie",
TRUE ~ "Gentoo"))
df_verification <- data.frame(df_penguins$species, clusters3$cluster)
colnames(df_verification) <- c("species", "cluster")
df_verification <- df_verification %>%
mutate(cluster_classification = case_when(cluster == 1 ~ "Chinstrap",
cluster == 2 ~ "Adelie",
TRUE ~ "Gentoo"))
# accuracy
mean(species == cluster_classification)
# accuracy
mean(df_verification$species == df_verification$cluster_classification)
call_on_folks <- sample(DBER_folks, 10000, replace = TRUE)
DBER_folks <- c("Petra", "Derek", "Carrie", "Brian", "Kristina", "Belinda",
"Kerry", "Cristie", "Michelle", "Erik", "Ambarish")
call_on_folks <- sample(DBER_folks, 10000, replace = TRUE)
DBER_folks <- c("Petra", "Derek", "Carrie", "Brian", "Kristina", "Belinda",
"Kerry", "Cristie", "Michelle", "Erik", "Ambarish")
call_on_folks <- sample(DBER_folks, 10000, replace = TRUE)
df <- data.frame(call_on_folks)
View(df)
DBER_folks <- c("Petra", "Derek", "Carrie", "Brian", "Kristina", "Belinda",
"Kerry", "Cristie", "Michelle", "Erik", "Ambarish")
call_on_folks <- sample(DBER_folks, 10000, replace = TRUE)
df <- data.frame(call_on_folks)
df_of_counts <- df %>% group_by(call_on_folks) %>% count()
library("tidyverse")
DBER_folks <- c("Petra", "Derek", "Carrie", "Brian", "Kristina", "Belinda",
"Kerry", "Cristie", "Michelle", "Erik", "Ambarish")
call_on_folks <- sample(DBER_folks, 10000, replace = TRUE)
df <- data.frame(call_on_folks)
df_of_counts <- df %>% group_by(call_on_folks) %>% count()
View(df_of_counts)
View(df_of_counts)
df_of_counts <-
ggplot(aes(x = call_on_folks, y = n)) +
geom_bar(stat = "identity")
df_of_counts %>%
ggplot(aes(x = call_on_folks, y = n)) +
geom_bar(stat = "identity")
df_of_counts %>%
ggplot(aes(x = call_on_folks, y = n, fill = call_on_folks)) +
geom_bar(stat = "identity") +
labs(title = "Can we use a Random Number Generator?"
subtitle = "'called' on people using an R function",
df_of_counts %>%
ggplot(aes(x = call_on_folks, y = n, fill = call_on_folks)) +
geom_bar(stat = "identity") +
labs(title = "Can we use a Random Number Generator?",
subtitle = "'called' on people using an R function",
caption = "DBER, May 6, 2021",
x = "audience member",
y = "number of times called on")
df_of_counts %>%
ggplot(aes(x = call_on_folks, y = n, fill = call_on_folks)) +
geom_bar(stat = "identity") +
labs(title = "Can we use a Random Number Generator?",
subtitle = "'called' on people using an R function",
caption = "DBER, May 6, 2021",
x = "audience member",
y = "number of times called on") +
theme_minimal() +
theme(legend.position = "none")
df_of_counts %>%
ggplot(aes(x = call_on_folks, y = n, fill = call_on_folks)) +
geom_bar(stat = "identity") +
labs(title = "Can we use a Random Number Generator?",
subtitle = "'called' on people using an R function",
caption = "DBER, May 6, 2021",
x = "audience member",
y = "number of times called on") +
theme_minimal() +
theme(legend.position = "none")
Q <- runif(6)
W <- Q / sum(Q)
round(W, 2)
Q <- runif(6)
W <- Q / sum(Q)
round(W, 2)
E <- round(W, 2)
sum(E)
3.2*3
3.2*5
sample(1:10)
(8)*(0.25) + (12)*(0.43) + (16)*(0.32)
1024+512
1536/2
(8)^2*(0.25) + (12)^2*(0.43) + (16)^2*(0.32)
(512)^2*(0.5) + (1024)^2*(0.5)
(8)*(512)*(0.15) + (12)*(512)*(0.32) + (16)*(512)*(0.03) + (8)*(1024)*(0.10) + (12)*(1024)*(0.11) + (16)*(1024)*(0.29)
159.84-12.28^2
655360-768^2
9748.48 - 12.25*768
340.48 / sqrt((9.0416)*(65536))
prod(dpois(c(2,4,3,1,5), 4))
library("tidyverse")
broadband <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-05-11/broadband.csv')
View(broadband)
broadband_subset <- broadband %>%
filter(ST == "CA" | ST == "TX")
View(broadband_subset)
broadband_subset <- broadband %>%
filter(ST == "CA" | ST == "TX")
colnames(broadband_subset) <- c("state", "county_ID", "county_name", "availability", "usage")
write.csv(broadband_subset, "broadband_data.csv")
# if you still don't have these code packages, you need to install.packages()
library("infer")
library("tidyverse")
df <- read_csv("broadband_data.csv")
colnames(df)
3 / ((0.05)*0.07^2))
3 / (0.05*0.07^2)
1 - exp(-4*32/45)
1 - (1 - exp(-52/45))^5
sqrt(6)*(49-45)/45
pnorm(0.2177)
pnorm(49, 45. 45/sqrt(6))
pnorm(49, 45, 45/sqrt(6))
512(0.15+0.32+0.29) + 1024(0.10+0.11+0.03)
512*(0.15+0.32+0.29) + 1024*(0.10+0.11+0.03)
2+4+3+1+6
16/5
exp(-4*52/32)
exp(-5*52/45)
150/180
library("DiagrammR")
install.packages("DiagrammeR")
library("DiagrammeR")
grViz("
digraph boxes_and_circles {
# a 'graph' statement
graph [overlap = true, fontsize = 10]
# several 'node' statements
node [shape = box,
fontname = Helvetica]
A; B; C; D; E; F
node [shape = circle,
fixedsize = true,
width = 0.9] // sets as circles
1; 2; 3; 4; 5; 6; 7; 8
# several 'edge' statements
A->1 B->2 B->3 B->4 C->A
1->D E->A 2->4 1->5 1->F
E->6 4->6 5->7 6->7 3->8
}
")
mermaid("
graph LR
A(Rounded)-->B[Rectangular]
B-->C{A Rhombus}
C-->D[Rectangle One]
C-->E[Rectangle Two]
")
mermaid("
graph TB
A{chicken} --> B(egg) --> C[fried egg]
")
mermaid("
graph TB
A{chicken} --> B(egg)
B --> C[fried egg]
")
mermaid("
graph LR
A{chicken} --> B(egg)
B --> C[fried egg]
D{cow} --> E(milk)
")
mermaid("
graph LR
A{chicken} --> B(egg)
B --> C[fried egg]
D{cow} --> E(milk)
F(potato) --> G[hashbrowns]
H(oil) --> G
")
mermaid("
graph LR
A{chicken} --> B(egg)
B --> C[fried egg]
D{cow} --> E(milk)
F(potato) --> G[hashbrowns]
H(oil) --> G
I(wheat flour) --> J[pancakes]
B --> J
")
mermaid("
graph LR
A{chicken} --> B(egg)
B --> C[fried egg]
D{cow} --> E(milk)
F(potato) --> G[hashbrowns]
H(oil) --> G
I(wheat flour) --> J[pancakes]
B --> J
C --> K[complete breakfast]
J --> K
E --> K
G --> K
")
mermaid("
graph LR
A{chicken} --> B(egg)
B --> C[fried egg]
D{cow} --> E(milk)
F(potato) --> G[hashbrowns]
H(oil) --> G
B --> J[pancakes]
I(wheat flour) --> J
C --> K[complete breakfast]
J --> K
E --> K
G --> K
")
mermaid("
graph LR
A{chicken} --> B(egg)
B --> C[fried egg]
D{cow} --> E(milk)
F(potato) --> G[hashbrowns]
H(oil) --> G
B --> J[pancakes]
I(wheat flour) --> J
C --> K[complete breakfast]
J --> K
E --> K
G --> K
")
library("Biostrings")
install.packages("Biostrings")
library("rtweet")
install.packages("rtweet")
library("rtweet")
library("tidyverse")
install.packages("tidyverse")
library("rtweet")    #to access Twitter
library("tidyverse") #data management
# the main code (only run sparingly if possible)
tweets_ucmerced <- search_tweets("#ucmerced", n = 1000, include_rts = FALSE)
View(tweets_ucmerced)
?search_tweets
tweets_ucm2021 <- search_tweets("#uc2021", n = 1000, include_rts = FALSE)
View(tweets_ucm2021)
tweets_ucm2021 <- search_tweets("#UCM2021", n = 1000, include_rts = FALSE)
View(tweets_ucm2021)
# the main code (only run sparingly if possible)
tweets_ucmerced <- search_tweets("#ucmerced", n = 1000, include_rts = FALSE)
tweets_ucm2021 <- search_tweets("#UCM2021", n = 1000, include_rts = FALSE)
tweets_uc2021grad <- search_tweets("#UC2021Grad", n = 1000, include_rts = FALSE)
tweets_newucgrad <- search_tweets("#NewUCGrad", n = 1000, include_rts = FALSE)
# the main code (only run sparingly if possible)
tweets_ucmerced <- search_tweets("uc merced", n = 1000, include_rts = FALSE)
View(tweets_ucmerced)
Sys.Date()
format(Sys.Date(), "%Y%m%d")
# save data for easy recall
write.csv(tweets_ucmerced,
paste0("tweets_ucmerced_", format(Sys.Date(), "%Y%m%d"), ".csv"))
?write.csv
paste0("tweets_ucmerced_", format(Sys.Date(), "%Y%m%d"), ".csv")
View(tweets_ucmerced)
write.csv(tweets_ucmerced, "scratch.csv")
tweets_ucmerced$text <- utf8_encode(tweets_ucmerced$text)
library("utf8")      #needed to ensure that some tweets were machine readable
# typecasting (to ease text mangagement)
tweets_ucmerced$text <- utf8_encode(tweets_ucmerced$text)
tweets_ucmerced_hashtag$text <- utf8_encode(tweets_ucmerced_hashtag$text)
tweets_ucmerced_hashtag   <- search_tweets("#ucmerced",   n = 1000, include_rts = FALSE)
tweets_ucmerced_hashtag$text <- utf8_encode(tweets_ucmerced_hashtag$text)
# save data for easy recall
write.csv(tweets_ucmerced,
paste0("tweets_ucmerced_", format(Sys.Date(), "%Y%m%d"), ".csv"))
write.csv(tweets_ucmerced_hashtag,
paste0("tweets_ucmerced_hashtag_", format(Sys.Date(), "%Y%m%d"), ".csv"))
library("rtweet")    #to access Twitter
library("tidyverse") #data management
library("utf8")      #needed to ensure that some tweets were machine readable
# the main code (only run sparingly if possible)
tweets_ucmerced_raw <- search_tweets("uc merced", n = 1000, include_rts = FALSE)
tweets_ucmerced_hashtag_raw   <- search_tweets("#ucmerced",   n = 1000, include_rts = FALSE)
colnames(tweets_ucmerced_raw)
View(tweets_ucmerced_raw)
# going from 90 variables to something more manageable
tweets_ucmerced <- tweets_ucmerced_raw %>%
select(created_at, screen_name, text,
favorite_count, retweet_count, media_expanded_url)
tweets_ucmerced_hashtag <- tweets_ucmerced_hashtag_raw %>%
select(created_at, screen_name, text,
favorite_count, retweet_count, media_expanded_url)
# typecasting (to ease text mangagement)
tweets_ucmerced$text <- utf8_encode(tweets_ucmerced$text)
tweets_ucmerced_hashtag$text <- utf8_encode(tweets_ucmerced_hashtag$text)
# save data for easy recall
write.csv(tweets_ucmerced,
paste0("tweets_ucmerced_", format(Sys.Date(), "%Y%m%d"), ".csv"))
str(tweets_ucmerced)
tweets_ucmerced$text <- utf8_encode(tweets_ucmerced$text)
tweets_ucmerced$media_expanded_url <- utf8_encode(tweets_ucmerced$media_expanded_url)
tweets_ucmerced$media_expanded_url <- unlist(tweets_ucmerced$media_expanded_url)
str(tweets_ucmerced)
tweets_ucmerced$text <- utf8_encode(tweets_ucmerced$text)
tweets_ucmerced$media_expanded_url <- unlist(tweets_ucmerced$media_expanded_url)
tweets_ucmerced_hashtag$text <- utf8_encode(tweets_ucmerced_hashtag$text)
tweets_ucmerced_hashtag$media_expanded_url <- unlist(tweets_ucmerced_hashtag$media_expanded_url)
# save data for easy recall
write.csv(tweets_ucmerced,
paste0("tweets_ucmerced_", format(Sys.Date(), "%Y%m%d"), ".csv"))
write.csv(tweets_ucmerced_hashtag,
paste0("tweets_ucmerced_hashtag_", format(Sys.Date(), "%Y%m%d"), ".csv"))
View(tweets_ucmerced_raw)
lookup_tweets("1405015936877293569")
library("kableExtra") #produces tables with better aesthetics
install.packages("kableExtra")
library("kableExtra") #produces tables with better aesthetics
tweets_ucmerced %>%
arrange(favorite_count) %>%
select(favorite_count, media_expanded_url, text)  %>%
kbl(caption = "UC Merced popular mentions") %>%
kable_classic(full_width = TRUE, html_font = "Cambria")
get_wd()
getwd()
devtools::install_github("daranzolin/rcanvas")
library(rcanvas)
set_canvas_token("1101~MJkKdL7QzQopQdmEor74p8NPKLC9S9CuGNQP6a6iv9UouICayNQppyRgfppEKTpy")
set_canvas_domain("https://catcourses.ucmerced.edu")
get_course_list()
knitr::opts_chunk$set(echo = TRUE)
library(rcanvas)
library(tidyverse)
course_id_df <- get_course_list()
course_id_df %>%
select(id, name, course_code) %>%
tidy()
course_id_df %>%
select(id, name, course_code)
course_id_df %>%
select(id, name, course_code)
?get_course_items
course_item_df <- get_course_items()
course_item_df <- get_course_items(course_id = 19703)
View(course_item_df)
course_item_df <- get_course_items(course_id = 19703, item = "quizzes")
View(course_item_df)
course_item_df %>%
select(id, title)
?get_submissions
get_submissions(ccourse_id = 19703, "quizzes", type_id = 30463)
midterm_submissions_df <- get_submissions(course_id = 19703, "quizzes", type_id = 30463)
View(midterm_submissions_df)
colnames(midterm_submissions_df)
midterm_submissions_df <- get_submissions(course_id = 19703, "quizzes", type_id = 30463)
colnames(midterm_submissions_df)
View(midterm_submissions_df)
library(janitor)
install.packages("janitor")
midterm_submissions_clean <- clean_names(midterm_submissions_df)
library(janitor)
midterm_submissions_clean <- clean_names(midterm_submissions_df)
View(midterm_submissions_df)
View(midterm_submissions_clean)
colnames(midterm_submissions_clean)
#midterm_submissions_clean <- clean_names(midterm_submissions_df)
colnames(midterm_submissions_df) <- gsub("\\.", "_",
colnames(midterm_submissions_df))
View(midterm_submissions_df)
midterm_submissions_df %>%
select(8, 10)
#midterm_submissions_clean <- clean_names(midterm_submissions_df)
names(midterm_submissions_df) <- gsub("\\.", "_",
names(midterm_submissions_df))
#midterm_submissions_clean <- clean_names(midterm_submissions_df)
#colnames(midterm_submissions_df) <- gsub("\\.", "_", colnames(midterm_submissions_df))
colnames(midterm_submissions_df) <- paste0("col", 1:27)
midterm_submissions_df <- get_submissions(course_id = 19703, "quizzes", type_id = 30463)
str(midterm_submissions_df)
#midterm_submissions_clean <- clean_names(midterm_submissions_df)
#colnames(midterm_submissions_df) <- gsub("\\.", "_", colnames(midterm_submissions_df))
#colnames(midterm_submissions_df) <- paste0("col", 1:27)
midterm_submissions_clean <- midterm_submissions_df$quiz_submissions
colnames(midterm_submissions_clean)
knitr::opts_chunk$set(echo = TRUE)
library("tidyverse")
pitcher_df <- read_csv("pitcher_data.csv")
pitcher_df <- read_csv("pitcher_data.csv")
knitr::opts_chunk$set(echo = TRUE)
library("kableExtra")
library("tidyverse")
pitcher_df %>%
kbl() %>%
kable_paper("hover", full_width = F)
pitcher_sums <- pitcher_df %>%
summarize(totalW = sum(W),
totalL = sum(L),
totalER = sum(ER),
totalIP = sum(IP))
pitcher_sums
pitcher_sums <- pitcher_df %>%
group_by(season) %>%
summarize(totalW = sum(W),
totalL = sum(L),
totalER = sum(ER),
totalIP = sum(IP))
pitcher_sums
pitcher_sums <- pitcher_sums %>%
mutate(ERA = 9*totalER / totalIP)
pitcher_sums
library("tidyverse")
# https://github.com/rfordatascience/tidytuesday/blob/master/data/2021/2021-08-03/readme.md
athletes <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-08-03/athletes.csv')
# https://github.com/rfordatascience/tidytuesday/blob/master/data/2021/2021-07-06/readme.md
holidays <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-07-06/holidays.csv')
# https://github.com/rfordatascience/tidytuesday/blob/master/data/2021/2021-07-13/readme.md
scoobydoo <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-07-13/scoobydoo.csv')
# https://github.com/rfordatascience/tidytuesday/blob/master/data/2021/2021-07-20/readme.md
drought <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-07-20/drought.csv')
# https://github.com/rfordatascience/tidytuesday/blob/master/data/2021/2021-07-27/readme.md
olympics <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-07-27/olympics.csv')
# https://github.com/rfordatascience/tidytuesday/blob/master/data/2021/2021-08-03/readme.md
athletes <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-08-03/athletes.csv')
?write_csv
write_csv(droughts, "droughts.csv")
write_csv(drought, "droughts.csv")
write_csv(holidays, "holidays.csv")
write_csv(olympics, "olympics.csv")
write_csv(athletes, "paraolympics.csv")
write_csv(scoobydoo, "scoobydoo.csv")
library("skimr")
install.packages('skimr')
drought <- read_csv("droughts.csv")
knitr::opts_chunk$set(echo = TRUE)
library("skimr")
library("tidyverse")
drought <- read_csv("droughts.csv")
drought <- read_csv("droughts.csv")
# skim a file
skim(drought)
skim_a_file <- function(file_name){
# This function will load and skim a file using the skimr package
# INPUT: file name (as a string)
# OUTPUT: none (displays information instead)
this_file <- read_csv(file_name)
skim(this_file)
}
?map_df
list.files(full.names = TRUE) %>%
map(skim_a_file)
list_of_files <- list.files()
list_of_files
list_of_files <- list.files(pattern = "\\.csv")
list_of_files
skim_a_file <- function(file_name){
# This function will load and skim a file using the skimr package
# INPUT: file name (as a string)
# OUTPUT: none (displays information instead)
print(file_name)
this_file <- read_csv(file_name)
skim(this_file)
}
skim_a_file("droughts.csv")
skim_a_file("drought.csv")
setwd("~/GitHub/quickblog/content/20210809SkimmingFiles")
skim_a_file("drought.csv")
skim_a_file("droughts.csv")
Q <- skim(athletes)
class(Q)
str(Q)
library("kableExtra")
skim(athletes)
skimg(drought)
skim(drought)
